{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LSTM_BigBirdA2C_GumbelSoftmax import *\n",
    "from dataset import make_data_generator\n",
    "import json\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "#from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'data/Food/'\n",
    "data_name = folder+'data.json'\n",
    "# validation_name = folder+'valid_seq.json'\n",
    "# testdata_name = folder+'testdata_seq.json'\n",
    "vocab_name = folder+'vocab.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "save_rate = 1 #how many epochs per modelsave\n",
    "#continue_from = \"trained/Model1\" # if none, put None\n",
    "continue_from = None\n",
    "epsilon = 1e-8\n",
    "validation_size = 10000\n",
    "device = torch.device('cuda')\n",
    "!mkdir -p trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = json.load(open(vocab_name, 'r'))\n",
    "VOC_SIZE = len(vocab)\n",
    "INPUT_MAX = 100\n",
    "SUMM_MAX = 101\n",
    "UNK = \"[UNK]\"\n",
    "BOS = \"[CLS]\"\n",
    "EOS = \"[SEP]\"\n",
    "PAD = \"[PAD]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading json\n",
      "load json done.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d59ead7de2734add987479c3b8bcf178",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=568454), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "batch_size = 72\n",
    "\n",
    "training_set, training_generator = make_data_generator(\\\n",
    "data_name, INPUT_MAX, SUMM_MAX, vocab[PAD], batch_size, pretrain=True, cutoff=None, shuffle=True, num_workers=4)\n",
    "\n",
    "# validation_set, validation_generator = make_data_generator(\\\n",
    "# validation_name, INPUT_MAX, OUTPUT_MAX, vocab[PAD], batch_size, cutoff=validation_size, shuffle=False, num_workers=4)\n",
    "\n",
    "def data_gen_train():\n",
    "    for src, tgt in training_generator:\n",
    "        src = src.to(device)\n",
    "        tgt = tgt.to(device)\n",
    "        b = Batch(src, tgt, vocab[PAD])\n",
    "        yield b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "total_train = int(math.ceil(training_set.size / batch_size))\n",
    "# total_valid = int(math.ceil(validation_set.size / batch_size))\n",
    "# print(total_train, total_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_param(model):\n",
    "    for p in model.parameters():\n",
    "        if p.dim() > 1:\n",
    "            nn.init.xavier_uniform_(p)\n",
    "\n",
    "model = LSTM_Normal_Encoder_Decoder(\n",
    "        hidden_dim=256, \n",
    "        emb_dim=256, \n",
    "        input_len=INPUT_MAX, \n",
    "        output_len=SUMM_MAX-1, \n",
    "        voc_size=len(vocab), \n",
    "        pad_index=vocab[PAD],\n",
    "        eps=1e-8\n",
    "    ).to(device)\n",
    "\n",
    "# init_param(model)\n",
    "\n",
    "from adabound import AdaBound\n",
    "model_opt = AdaBound(model.parameters(), lr=1e-4, betas=(0.9, 0.998), final_lr=0.1, eps=1e-8)\n",
    "# model_opt = torch.optim.Adam(model.parameters(), lr=1e-4, betas=(0.9, 0.998), eps=1e-8)\n",
    "criterion = torch.nn.NLLLoss(reduction='sum', ignore_index = vocab[PAD]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install adabound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_inv = {a:b for b, a in vocab.items()}\n",
    "def convert_ids_to_tokens(ids):\n",
    "    return [vocab_inv[i] for i in ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bf84c06e9d74ef7b5983f51f60bc1bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7896), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "\n",
      "\n",
      "['i', 'are', 'a', 'a', 'the', '.', 'the', 'best', '.', '.', 'and', 'i', 'is', 'a', 'to', '.', '.', 'be', 'a', 'a', '.', '.', 'be', 'a', '[SEP]', \"'\", 'to', '.', 'be', '.', 'a', '.', '.', '.', '.', '.', '.', 'you', 'and', 'a', '.', '.', 'the', '.', 'be', 'best', '.', '[SEP]', 'is', 'is', 'the', 'little', '.', '[SEP]', \"'\", 'the', 'to', '.', 'little', '.', '.', '.', \"'\", 'the', '.', '.', '.', 'is', 'the', 'best', '.', '.', '.', '.', 'be', '.', '.', '.', '[SEP]']\n",
      "['these', 'cost', 'more', 'on', 'amazon', 'than', 'the', 'grocery', 'store', ',', 'but', 'it', 'is', 'sometimes', 'more', 'convenient', 'to', 'just', 'have', 'them', 'shipped', 'to', 'you', '.', 'we', 'used', 'these', 'to', 'help', 'our', 'baby', 'feel', '\"', 'more', 'comfortable', '\"', 'if', 'she', 'was', 'having', 'issues', 'with', 'going', 'to', 'the', 'bathroom', '.', 'this', 'worked', 'like', 'a', 'charm', '.', 'we', 'ended', 'up', 'having', 'a', 'regular', 'rotation', 'where', 'we', 'made', 'sure', 'she', 'got', 'this', 'in', 'the', 'morning', 'every', 'few', 'days', 'to', 'prevent', 'any', 'problems', '.', '[SEP]']\n",
      "\n",
      "\n",
      "['i', 'is', 'a', 'great', 'of', ',', ',', ',', 'i', \"'\", \"'\", 't', 'have', 'to', ',', 'and', 'i', \"'\", 'not', 'to', 'best', ',', ',', ',', 'the', '.', 'i', 'is', 'a', 'good', '##sty', ',', 'i', 'a', 'little', 'of', ',', 'i', 'great', ',', 'a', ',', ',', ',', 'and', 'i', ',', ',', ',', '.', '.', 'and', ',', ',', ',', '.', 'i', '.', '.', 'and', 'i', \"'\", 's', 'a', 'great', 'of', '.', '.', 'a', ',', '.', 'i', 'br', '/', '>', 'i', 'br', '/', '>', 'i', ',', ',', 'taste', 'is', ',', \"'\", 's', 'be', 'i', 'to', 'be', 'to', 'a', 'and', 'little', ',', 'a', '.', 'be', '.']\n",
      "['this', 'is', 'a', 'pretty', 'good', 'snack', 'food', '.', 'i', 'don', \"'\", 't', 'miss', 'meat', ',', 'but', 'i', 'do', 'miss', 'the', 'season', '##ings', 'put', 'on', 'it', '.', 'this', 'is', 'very', 'ta', '##sty', 'and', 'has', 'a', 'nice', 'texture', '.', 'a', 'packet', 'is', '4', 'serving', '##s', ',', 'and', '100', 'cal', '##ories', 'per', 'serving', ',', 'pretty', 'much', 'equal', 'protein', 'and', 'car', '##bs', ',', 'so', 'it', \"'\", 's', 'a', 'high', 'protein', 'food', 'for', 'most', 'people', '.', '<', 'br', '/', '>', '<', 'br', '/', '>', 'problems', ':', 'the', 'inner', 'packaging', 'isn', \"'\", 't', 'that', 'easy', 'to', 'deal', 'with', ',', 'a', 'knife', 'is', 'needed', 'to', 'cut', 'it']\n"
     ]
    }
   ],
   "source": [
    "start = 1 if continue_from == None else (int(continue_from.split(\"Model\")[-1])+1)\n",
    "history = []\n",
    "\n",
    "\n",
    "for epoch in range(start, num_epochs+1):\n",
    "    print(\"Epoch\", epoch)\n",
    "    \n",
    "    # training\n",
    "    stats = Stats()\n",
    "    model.train()\n",
    "    trange = tqdm(enumerate(data_gen_train()), total=total_train)\n",
    "    \n",
    "    for i, batch in trange:\n",
    "        \n",
    "        #r, _, next_words = model(\n",
    "        #    x=batch.src, \n",
    "        #    src_mask=batch.src_mask, \n",
    "        #    max_len=batch.trg_y.shape[1], \n",
    "        #    start_symbol=vocab[BOS], \n",
    "        #    y=batch.trg_y.contiguous(), \n",
    "        #    mode = 'sample'\n",
    "        #)\n",
    "        \n",
    "        logits, next_words = model.pretrian_forward(\n",
    "            x=batch.src,\n",
    "            y=batch.trg,\n",
    "            mode = 'sample'\n",
    "        )\n",
    "        N = (batch.trg_y.shape[0]*batch.trg_y.shape[1])\n",
    "        loss = criterion(logits.view(N, len(vocab)), batch.trg_y.contiguous().view(N)) / batch.ntokens\n",
    "    \n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        model_opt.step()\n",
    "        \n",
    "        stats.update(loss, 1, log=0)\n",
    "        \n",
    "        if( i % 1000 == 999):\n",
    "            print(\"\\n\")            \n",
    "            print(convert_ids_to_tokens([i.item() for i in next_words[0]]))\n",
    "            print(convert_ids_to_tokens([i.item() for i in batch.trg_y[0]]))\n",
    "        \n",
    "        trange.set_postfix(\n",
    "            **{'loss': '{:.3f}'.format(loss)},\n",
    "            **{'tgt_len': '{}'.format(batch.trg_y.shape[1])}\n",
    "        )\n",
    "        \n",
    "    t_h = stats.history\n",
    "    history.append(t_h)\n",
    "    \n",
    "    print(\"[info] epoch train loss:\", np.mean(t_h))\n",
    "    \n",
    "    try:\n",
    "        !mkdir -p pretrained\n",
    "        torch.save({'model':translator.state_dict(), 'training_history':t_h}, \n",
    "                   \"pretrained/LSTM\"+str(epoch))\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = np.asarray(history).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
