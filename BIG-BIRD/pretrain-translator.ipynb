{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer_nb2 import *\n",
    "from dataset import make_data_generator\n",
    "import json\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "#from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'data/IMDB/'\n",
    "data_name = folder+'data.json'\n",
    "# validation_name = folder+'valid_seq.json'\n",
    "# testdata_name = folder+'testdata_seq.json'\n",
    "vocab_name = folder+'vocab.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "save_rate = 1 #how many epochs per modelsave\n",
    "#continue_from = \"trained/Model1\" # if none, put None\n",
    "continue_from = None\n",
    "epsilon = 1e-8\n",
    "validation_size = 10000\n",
    "device = torch.device('cuda')\n",
    "!mkdir -p trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = json.load(open(vocab_name, 'r'))\n",
    "VOC_SIZE = len(vocab)\n",
    "INPUT_MAX = 300\n",
    "SUMM_MAX = 20\n",
    "UNK = \"[UNK]\"\n",
    "BOS = \"[CLS]\"\n",
    "EOS = \"[SEP]\"\n",
    "PAD = \"[PAD]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading json\n",
      "load json done.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e9f919811a246f68819beada18762d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=25000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "training_set, training_generator = make_data_generator(\\\n",
    "data_name, INPUT_MAX, SUMM_MAX, vocab[PAD], batch_size, cutoff=None, shuffle=True, num_workers=4)\n",
    "\n",
    "# validation_set, validation_generator = make_data_generator(\\\n",
    "# validation_name, INPUT_MAX, OUTPUT_MAX, vocab[PAD], batch_size, cutoff=validation_size, shuffle=False, num_workers=4)\n",
    "\n",
    "def data_gen_train():\n",
    "    for src, label, tgt in training_generator:\n",
    "        src = src.to(device)\n",
    "        label = (label).long().to(device)\n",
    "        tgt = tgt.to(device)\n",
    "        b = Batch(src, tgt, vocab[PAD])\n",
    "        b.label = label\n",
    "        yield b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "total_train = int(math.ceil(training_set.size / batch_size))\n",
    "# total_valid = int(math.ceil(validation_set.size / batch_size))\n",
    "# print(total_train, total_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/george/.conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/_reduction.py:49: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "def init_param(model):\n",
    "    for p in model.parameters():\n",
    "        if p.dim() > 1:\n",
    "            nn.init.xavier_uniform_(p)\n",
    "\n",
    "# translator = PointerGenerator(\n",
    "#             hidden_dim=256, \n",
    "#             emb_dim=256, \n",
    "#             input_len=INPUT_MAX, \n",
    "#             output_len=SUMM_MAX, \n",
    "#             voc_size=VOC_SIZE, \n",
    "#             eps=1e-8\n",
    "#         ).to(device)\n",
    "translator = make_model(VOC_SIZE, VOC_SIZE, N=4, d_model=256, d_ff=512, h=8, dropout=0.1, emb_share=True).to(device)\n",
    "\n",
    "criterion = LabelSmoothing(size=VOC_SIZE, padding_idx=vocab[PAD], smoothing=0.1).to(device)\n",
    "model_opt = torch.optim.Adam(translator.parameters(), lr=1e-4, betas=(0.9, 0.998), eps=1e-8)\n",
    "loss_compute = SimpleLossCompute(translator.generator, criterion, model_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.nn.functional as F\n",
    "# def loss_compute(x, y, norm): \n",
    "#     x = F.log_softmax(x)\n",
    "    \n",
    "#     print(x.shape)\n",
    "    \n",
    "#     loss = criterion(x.contiguous().view(-1, x.size(-1)), \n",
    "#                           y.contiguous().view(-1)) / norm\n",
    "#     loss.backward()\n",
    "#     if model_opt is not None:\n",
    "#         model_opt.step()\n",
    "#         model_opt.zero_grad()\n",
    "#     return loss.item() * norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = make_big_bird(vocab, N=4, d_model=256, d_ff=512, h=8, dropout=0.1, emb_share=True, bert_share=True)\n",
    "#model.load(\"Nest/NewbornBird\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_inv = {a:b for b, a in vocab.items()}\n",
    "def convert_ids_to_tokens(ids):\n",
    "    return [vocab_inv[i] for i in ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43f0f098ecd440ac9c5f65504e2b49d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=391), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 1 Loss: 8.938125 Tokens / Sec: 1952.920921\n",
      "\n",
      "['examines', 'suppressed', 'vu', 'vu', 'vu', 'directive', '##tower', 'vu', 'examines', 'vu', 'maple', 'vu', 'directive', 'examines', 'directive', 'examines', 'examines', '##face', 'manipulating']\n",
      "Step: 301 Loss: 6.060853 Tokens / Sec: 4604.086642\n",
      "\n",
      "['the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the']\n",
      "Step: 601 Loss: 5.844194 Tokens / Sec: 4644.664581\n",
      "\n",
      "['i', 'i', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', ',', '.', ',', '.', '.', '.', '.', 'the', 'the']\n",
      "Step: 781 Loss: 5.839874 Tokens / Sec: 4381.967525\n",
      "[info] epoch train loss: 3820.1237792560205\n",
      "Epoch 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7100aafa09664e2d8c58b8dd9503b03a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=391), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 1 Loss: 5.628731 Tokens / Sec: 3313.561526\n",
      "\n",
      "['i', 'movie', 'the', 'movie', ',', 'the', 'movie', ',', ',', ',', 'the', ',', 'the', ',', ',', ',', ',', 's', ',']\n",
      "Step: 301 Loss: 5.134790 Tokens / Sec: 4594.625895\n",
      "\n",
      "['i', 'movie', 'of', 'a', 'movie', 'movie', 'movie', 'the', 'movie', 'movie', ',', 'the', '.', 'movie', ',', '.', \"'\", 's', \"'\"]\n",
      "Step: 601 Loss: 4.951511 Tokens / Sec: 4595.292388\n",
      "\n",
      "['i', \"'\", 'to', 'movie', '.', 'the', '.', 'i', 'have', 'to', 'i', \"'\", ',', '.', 'the', '.', 'i', \"'\", \"'\"]\n",
      "Step: 781 Loss: 4.974915 Tokens / Sec: 4039.710652\n",
      "[info] epoch train loss: 3143.7551068290113\n",
      "Epoch 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "104b651b9fd743e0b3f0861384149d8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=391), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 1 Loss: 4.746830 Tokens / Sec: 2922.777856\n",
      "\n",
      "['i', 'is', 'a', 'movie', '.', 'i', \"'\", 'have', 'to', 'this', 'this', 'movie', '.', 'a', '.', '.', 'i', 'br', '/']\n",
      "Step: 301 Loss: 4.487877 Tokens / Sec: 4590.064990\n",
      "\n",
      "['<', 'to', 'the', 'the', 'movie', '.', '<', 'br', '/', '>', '<', 'br', '/', '>', '<', '/', '<', '/', '/']\n",
      "Step: 601 Loss: 4.224488 Tokens / Sec: 4570.760233\n",
      "\n",
      "['\"', 'an', \"'\", 'be', 'the', 'the', 'best', 'of', 'the', 'movie', '.', '.', \"'\", 's', 'the', '.', '.', '.', 'the']\n",
      "Step: 781 Loss: 3.971101 Tokens / Sec: 4264.003628\n",
      "[info] epoch train loss: 2672.324607294234\n",
      "Epoch 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ed4b1fa1c324e2d8d000219a8475b8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=391), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 1 Loss: 3.925173 Tokens / Sec: 2956.594687\n",
      "\n",
      "['\"', '\"', ',', ',', '\"', ',', 'the', 'story', ',', 'is', 'a', 'great', 'be', 'be', '-', '-', ',', 'i', \"'\"]\n",
      "Step: 301 Loss: 3.717526 Tokens / Sec: 4614.709333\n",
      "\n",
      "['this', 'film', 'is', 'with', 'with', 'great', 'and', 'and', 'all', '##s', 'to', 'the', 'years', 'it', 'i', 'was', 'it', ',', ',']\n",
      "Step: 601 Loss: 3.216745 Tokens / Sec: 4552.454100\n",
      "\n",
      "['\"', 'the', 'best', '##o', 'film', '\"', 'is', 'not', '.', 'not', 'not', 'in', 'the', 'best', 'films', '\"', '\"', '\"', '\"']\n",
      "Step: 781 Loss: 2.825870 Tokens / Sec: 3887.508006\n",
      "[info] epoch train loss: 2099.927055443339\n",
      "Epoch 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9464ab5a719a46c8b5dc30a01b4af7a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=391), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 1 Loss: 3.240874 Tokens / Sec: 3211.919021\n",
      "\n",
      "['this', 'is', 'what', 'not', 'like', 'a', '\"', 'two', '-', '##s', '##s', 'man', '-', '\"', 'movie', '.', 'it', 'has', 'no']\n",
      "Step: 301 Loss: 2.871978 Tokens / Sec: 4722.497478\n",
      "\n",
      "['so', 'it', 'has', 'been', 'to', 'this', '.', 'many', ',', 'made', 'made', 'that', 'have', 'the', 'the', 'old', '?', 'can', 'ever']\n",
      "Step: 601 Loss: 2.452463 Tokens / Sec: 4599.092192\n",
      "\n",
      "['if', 'i', 'don', \"'\", 't', 'been', 'going', 'to', 'watch', 'this', 'for', 'time', 'movies', 'i', 'had', 'have', 'have', 'made', 'it']\n",
      "Step: 781 Loss: 2.088028 Tokens / Sec: 4556.022188\n",
      "[info] epoch train loss: 1629.7161681688656\n",
      "Epoch 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7328b0d81912484bbaa0420d944043cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=391), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 1 Loss: 2.510001 Tokens / Sec: 3307.201573\n",
      "\n",
      "['this', 'is', 'a', 'a', 's', \"'\", '.', 'it', 'it', 'di', '##l', '.', 'the', 'acting', 'is', 'by', 'and', 'its', \"'\"]\n",
      "Step: 301 Loss: 1.975900 Tokens / Sec: 4678.853966\n",
      "\n",
      "['un', '##re', '##re', '##es', '##l', '##l', 'of', 'a', 'story', '.', '<', 'br', '/', '>', '<', 'br', '/', '>', 'it']\n",
      "Step: 601 Loss: 2.047327 Tokens / Sec: 4648.101684\n",
      "\n",
      "['actually', ',', 'i', 'never', 'found', 'into', 'the', 'original', 'was', 'un', 'and', 'and', 'characters', ',', 'but', 'this', 'movie', 'kind', 'of']\n",
      "Step: 781 Loss: 1.896146 Tokens / Sec: 4046.818755\n",
      "[info] epoch train loss: 1279.4530738756785\n",
      "Epoch 7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3a2b5ff17254223806d43119317ad6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=391), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 1 Loss: 1.992176 Tokens / Sec: 3065.788694\n",
      "\n",
      "['i', 'actually', 'wanted', 'to', 'see', 'this', 'movie', 'in', 'the', 'music', '.', 'it', 'was', 'actually', 'up', 'out', '.', 'i', 'actually']\n",
      "Step: 301 Loss: 1.610950 Tokens / Sec: 4697.976537\n",
      "\n",
      "['about', 'years', 'years', 'ago', ',', 'i', 'liked', 'this', 'movie', '.', 'i', 'would', 'watch', 'it', 'over', 'over', 'since', 'and', 'over']\n",
      "Step: 601 Loss: 1.680174 Tokens / Sec: 4636.460683\n",
      "\n",
      "['for', 'those', 'who', 'never', 'saw', 'a', 'bit', 'line', 'of', 'and', 'their', 'only', 'wanted', 'to', 'the', 'story', 'was', 'this', 'film']\n",
      "Step: 781 Loss: 1.437979 Tokens / Sec: 4460.027759\n",
      "[info] epoch train loss: 1022.1669812295443\n",
      "Epoch 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13d7358a2d4644faadb289f4c19173f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=391), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 1 Loss: 1.364286 Tokens / Sec: 3296.411411\n",
      "\n",
      "['ok', ',', 'i', 'have', 'to', 'admit', 'that', 'i', 'have', 'never', 'seen', '\"', 'r', 'don', '##en', '\"', 'and', 'only', 'one']\n",
      "Step: 301 Loss: 1.324998 Tokens / Sec: 4695.546827\n",
      "\n",
      "['this', 'movie', 'is', 'finally', 'out', 'on', 'dvd', 'in', 'course', '(', 'completely', ')', ')', '.', 'i', 'have', 'seen', 'this', 'movie']\n",
      "Step: 601 Loss: 1.200646 Tokens / Sec: 4736.219422\n",
      "\n",
      "['this', 'is', 'an', 'ok', 'film', 'but', 'takes', 'any', 'real', 'heart', 'either', 'mr', 'or', 'in', 'each', 'of', 'story', 'showing', '.']\n",
      "Step: 781 Loss: 1.130839 Tokens / Sec: 4541.314182\n",
      "[info] epoch train loss: 828.6442471520065\n",
      "Epoch 9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe0a61bf3ca641ba8f92a5383b9d7872",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=391), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 1 Loss: 1.318777 Tokens / Sec: 3318.846368\n",
      "\n",
      "['although', '##nic', '##ic', 'film', 'with', 'a', 'spoil', '##re', '##y', 'slow', 'start', '-', 'give', 'it', 'a', 'chance', 'to', 'start', '5']\n",
      "Step: 301 Loss: 1.199452 Tokens / Sec: 4632.283342\n",
      "\n",
      "['right', 'at', 'this', 'moment', 'i', 'am', 'watching', 'this', 'movie', 'for', 'the', 'second', 'time', '(', 'on', 'television', ')', 'and', 'for']\n",
      "Step: 601 Loss: 0.987085 Tokens / Sec: 4730.372709\n",
      "\n",
      "['during', 'the', 'opening', 'night', 'of', 'the', 'van', '##gal', 'a', 'woman', 'is', 'found', 'dead', 'on', 'the', 'cat', 'against', 'above', 'the']\n",
      "Step: 781 Loss: 1.139729 Tokens / Sec: 4474.125210\n",
      "[info] epoch train loss: 680.3291429493129\n",
      "Epoch 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9a4fe8afba54a5a98dc7e66e34095a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=391), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 1 Loss: 0.993821 Tokens / Sec: 3246.894394\n",
      "\n",
      "['i', \"'\", 've', 'had', 'a', 'thing', 'for', 'this', 'several', 'gem', 'for', 'a', 'while', ',', 'and', 'as', 'far', 'as', 'how']\n",
      "Step: 301 Loss: 0.967576 Tokens / Sec: 4672.694116\n",
      "\n",
      "['in', 'atlantis', ',', 'carr', '##g', 'once', 'again', 'tries', 'to', 'take', 'a', 'whole', '##ta', '##ble', 'between', 'reality', 'and', 'fiction', ',']\n",
      "Step: 601 Loss: 0.850285 Tokens / Sec: 4386.773696\n",
      "\n",
      "['before', 'i', 'begin', ',', 'i', 'want', 'to', 'give', 'say', 'that', 'this', 'movie', 'in', 'and', 'of', 'itself', 'is', 'very', 'well']\n",
      "Step: 781 Loss: 1.000378 Tokens / Sec: 4120.631447\n",
      "[info] epoch train loss: 564.4049405319154\n"
     ]
    }
   ],
   "source": [
    "start = 1 if continue_from == None else (int(continue_from.split(\"Model\")[-1])+1)\n",
    "history = []\n",
    "\n",
    "\n",
    "for epoch in range(start, num_epochs+1):\n",
    "    print(\"Epoch\", epoch)\n",
    "    \n",
    "    # training\n",
    "    stats = Stats()\n",
    "    translator.train()\n",
    "    trange = tqdm(enumerate(data_gen_train()), total=total_train)\n",
    "    \n",
    "    for i, batch in trange:\n",
    "        out = translator.forward(batch.src, batch.trg, batch.src_mask, batch.trg_mask)\n",
    "        loss = loss_compute(out, batch.trg_y, batch.ntokens)\n",
    "        stats.update(loss, batch.ntokens, log=1)\n",
    "        \n",
    "        if( i % 150 == 0):\n",
    "            probs = translator.generator(out) \n",
    "            print(\"\\n\")\n",
    "            next_words = torch.argmax(probs, dim=-1, keepdim=True)            \n",
    "            print(convert_ids_to_tokens([i.item() for i in next_words[0]]))\n",
    "        \n",
    "        trange.set_postfix(\n",
    "            **{'loss': '{:.3f}'.format(loss)}\n",
    "        )\n",
    "        stats.update(loss, 1, log=0)\n",
    "        \n",
    "    t_h = stats.history\n",
    "    history.append(t_h)\n",
    "    \n",
    "    print(\"[info] epoch train loss:\", np.mean(t_h))\n",
    "    \n",
    "    try:\n",
    "        torch.save({'model':translator.state_dict(), 'training_history':t_h}, \n",
    "                   \"pretrained/Translator\"+str(epoch))\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
