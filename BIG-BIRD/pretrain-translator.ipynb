{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer_nb2 import *\n",
    "from dataset import make_data_generator\n",
    "import json\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "#from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'data/food/'\n",
    "data_name = folder+'data.json'\n",
    "# validation_name = folder+'valid_seq.json'\n",
    "# testdata_name = folder+'testdata_seq.json'\n",
    "vocab_name = folder+'vocab.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "save_rate = 1 #how many epochs per modelsave\n",
    "#continue_from = \"trained/Model1\" # if none, put None\n",
    "continue_from = None\n",
    "epsilon = 1e-8\n",
    "validation_size = 10000\n",
    "device = torch.device('cuda')\n",
    "!mkdir -p trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = json.load(open(vocab_name, 'r'))\n",
    "VOC_SIZE = len(vocab)\n",
    "INPUT_MAX = 100\n",
    "SUMM_MAX = 100\n",
    "UNK = \"[UNK]\"\n",
    "BOS = \"[CLS]\"\n",
    "EOS = \"[SEP]\"\n",
    "PAD = \"[PAD]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading json\n",
      "load json done.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79c3b1a16b3a4016bef7e1356db2f86e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=568454), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(tensor([ 4149,  1997,  3504,  1997,  3012,  1998,  3899,  2084,  2026,  2062,\n",
      "         6799,  2009,  1045,  2031, 13995,  8995,  2022,  1037,  1037,  2023,\n",
      "         2833,  2003,  2084,  2100, 20717,  2195,  1012,  4031,   102,  2066,\n",
      "         1996,  1998,  2000,  1996,  2035,  2204, 14747,  2488,  2087,  9120,\n",
      "        10346,  2016, 27141,  4031,  3688,  1012,  2179,  1998,   101,  6240,\n",
      "         2068,  2015,  1012, 18604,  2031,  3737,  2488,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0]), tensor([  101,  1045,  2031,  4149,  2195,  1997,  1996,  8995,  3012, 27141,\n",
      "         3899,  2833,  3688,  1998,  2031,  2179,  2068,  2035,  2000,  2022,\n",
      "         1997,  2204,  3737,  1012,  1996,  4031,  3504,  2062,  2066,  1037,\n",
      "        20717,  2084,  1037, 13995,  6240,  1998,  2009, 14747,  2488,  1012,\n",
      "         2026, 18604,  2003, 10346,  6799,  2100,  1998,  2016,  9120,  2015,\n",
      "         2023,  4031,  2488,  2084,  2087,  1012,   102,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0]))\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "training_set, training_generator = make_data_generator(\\\n",
    "data_name, INPUT_MAX, SUMM_MAX, vocab[PAD], batch_size, pretrain=True, cutoff=None, shuffle=True, num_workers=4)\n",
    "\n",
    "# validation_set, validation_generator = make_data_generator(\\\n",
    "# validation_name, INPUT_MAX, OUTPUT_MAX, vocab[PAD], batch_size, cutoff=validation_size, shuffle=False, num_workers=4)\n",
    "\n",
    "def data_gen_train():\n",
    "    for src, tgt in training_generator:\n",
    "        src = src.to(device)\n",
    "        tgt = tgt.to(device)\n",
    "        b = Batch(src, tgt, vocab[PAD])\n",
    "        yield b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "total_train = int(math.ceil(training_set.size / batch_size))\n",
    "# total_valid = int(math.ceil(validation_set.size / batch_size))\n",
    "# print(total_train, total_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marvin/anaconda3/envs/py37cuda10/lib/python3.7/site-packages/torch/nn/_reduction.py:49: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "def init_param(model):\n",
    "    for p in model.parameters():\n",
    "        if p.dim() > 1:\n",
    "            nn.init.xavier_uniform_(p)\n",
    "\n",
    "# translator = PointerGenerator(\n",
    "#             hidden_dim=256, \n",
    "#             emb_dim=256, \n",
    "#             input_len=INPUT_MAX, \n",
    "#             output_len=SUMM_MAX, \n",
    "#             voc_size=VOC_SIZE, \n",
    "#             eps=1e-8\n",
    "#         ).to(device)\n",
    "translator = make_model(VOC_SIZE, VOC_SIZE, N=4, d_model=128, d_ff=256, h=4, dropout=0.1, emb_share=True).to(device)\n",
    "\n",
    "criterion = LabelSmoothing(size=VOC_SIZE, padding_idx=vocab[PAD], smoothing=0.1).to(device)\n",
    "model_opt = torch.optim.Adam(translator.parameters(), lr=1e-4, betas=(0.9, 0.998), eps=1e-8)\n",
    "loss_compute = SimpleLossCompute(translator.generator, criterion, model_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.nn.functional as F\n",
    "# def loss_compute(x, y, norm): \n",
    "#     x = F.log_softmax(x)\n",
    "    \n",
    "#     print(x.shape)\n",
    "    \n",
    "#     loss = criterion(x.contiguous().view(-1, x.size(-1)), \n",
    "#                           y.contiguous().view(-1)) / norm\n",
    "#     loss.backward()\n",
    "#     if model_opt is not None:\n",
    "#         model_opt.step()\n",
    "#         model_opt.zero_grad()\n",
    "#     return loss.item() * norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = make_big_bird(vocab, N=4, d_model=256, d_ff=512, h=8, dropout=0.1, emb_share=True, bert_share=True)\n",
    "#model.load(\"Nest/NewbornBird\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_inv = {a:b for b, a in vocab.items()}\n",
    "def convert_ids_to_tokens(ids):\n",
    "    return [vocab_inv[i] for i in ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3f5bfed21ab41c7a0317669a812bbd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=8883), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 1 Loss: 8.957157 Tokens / Sec: 8958.600531\n",
      "\n",
      "['rector', 'greatest', '##oin', 'list', 'dramas', 'induced', 'newsletter', '##ype', 'cared', '##ype', 'greatest', 'undo', 'greatest', 'cared', 'bra', 'cared', '##np', 'newsletter', 'elector', '##np', 'induced', 'newsletter', 'dramas', '747', 'valid', 'greatest', 'cared', 'greatest', 'cared', 'greatest', 'dramas', 'feeding', '##lford', 'greatest', 'depression', 'cared', 'cared', 'pba', 'offs', 'crew', 'valid', 'cared', 'feeding', 'feeding', 'list', 'art', 'greatest', 'baba', 'greatest', 'agreement', 'dramas', 'greatest', 'newsletter', 'baba', '##np', 'depression', 'greatest', 'greatest', 'greatest', 'elector', 'pba', 'pba', 'agreement', 'depression', '##plicity', 'crew', '##wan', 'pba', '##np', 'art', 'art', 'elector', 'pba', '##wan', 'depression', '##wan', 'greatest', 'depression', '##wan', '##wan', '##wan', '##wan', 'dramas', 'newborn', 'managing', 'agreement', '##wan', '##wan', 'pba', 'feeding', '##wan', 'newsletter', 'managing', 'feeding', '##wan', 'feeding', 'feeding', 'managing', '##wan']\n",
      "['even', 'though', 'everyone', 'talks', 'about', 'natural', 'as', 'the', 'most', 'popular', 'z', '##ico', 'flavor', ',', 'this', 'is', 'by', 'far', 'my', 'favorite', '.', 'it', \"'\", 's', 'light', ',', 'refreshing', 'and', 'has', 'about', '40', '%', 'less', 'sugar', 'and', 'cal', '##ories', 'than', 'other', 'flavor', '##ed', 'coconut', 'waters', 'because', 'z', '##ico', 'doesn', \"'\", 't', 'add', 'juice', 'and', 'pure', '##e', 'like', 'the', 'other', 'brands', '.', 'by', 'the', 'way', ',', 'it', 'is', 'also', 'awesome', 'as', 'a', 'mixer', '(', 'or', 'so', 'i', 'hear', ')', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "Step: 283 Loss: 6.799314 Tokens / Sec: 45412.324010\r"
     ]
    }
   ],
   "source": [
    "start = 1 if continue_from == None else (int(continue_from.split(\"Model\")[-1])+1)\n",
    "history = []\n",
    "\n",
    "\n",
    "for epoch in range(start, num_epochs+1):\n",
    "    print(\"Epoch\", epoch)\n",
    "    \n",
    "    # training\n",
    "    stats = Stats()\n",
    "    translator.train()\n",
    "    trange = tqdm(enumerate(data_gen_train()), total=total_train)\n",
    "    \n",
    "    for i, batch in trange:\n",
    "        out = translator.forward(batch.src, batch.trg, batch.src_mask, batch.trg_mask)\n",
    "        loss = loss_compute(out, batch.trg_y, batch.ntokens)\n",
    "        stats.update(loss, batch.ntokens, log=1)\n",
    "        \n",
    "        if( i % 150 == 0):\n",
    "            probs = translator.generator(out) \n",
    "            print(\"\\n\")\n",
    "            next_words = torch.argmax(probs, dim=-1, keepdim=True)            \n",
    "            print(convert_ids_to_tokens([i.item() for i in next_words[0]]))\n",
    "            print(convert_ids_to_tokens([i.item() for i in batch.trg_y[0]]))\n",
    "        \n",
    "        trange.set_postfix(\n",
    "            **{'loss': '{:.3f}'.format(loss)}\n",
    "        )\n",
    "        stats.update(loss, 1, log=0)\n",
    "        \n",
    "    t_h = stats.history\n",
    "    history.append(t_h)\n",
    "    \n",
    "    print(\"[info] epoch train loss:\", np.mean(t_h))\n",
    "    \n",
    "    try:\n",
    "        !mkdir -p pretrained\n",
    "        torch.save({'model':translator.state_dict(), 'training_history':t_h}, \n",
    "                   \"pretrained/Translator\"+str(epoch))\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = np.asarray(history).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
