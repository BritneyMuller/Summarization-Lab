{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from PointerGenerator import PointerGenerator\n",
    "# from tqdm import tqdm\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'preprocessing-cnn-all/'\n",
    "data_name = folder+'train_seq.json'\n",
    "validation_name = folder+'valid_seq.json'\n",
    "testdata_name = folder+'testdata_seq.json'\n",
    "vocab_name = folder+'vocab.json'\n",
    "wv_name = folder+'wv_matrix'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_DIM = 256\n",
    "EMB_DIM = 50\n",
    "INPUT_MAX = 400\n",
    "OUTPUT_MAX = 100\n",
    "num_epochs = 12\n",
    "save_rate = 1 #how many epochs per modelsave\n",
    "clip_grad_norm = 5. #maximum gradient norm\n",
    "continue_from = \"models/covModel5\" # if none, put None\n",
    "# continue_from = None\n",
    "epsilon = 1e-10\n",
    "validation_size = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = json.load(open(vocab_name, 'r'))\n",
    "VOC_SIZE = len(vocab)\n",
    "# word_vectors = np.load(wv_name+\".npy\")\n",
    "word_vectors = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab={'<pad>':0, '<bos>': 1, '<eos>': 2, '<unk>': 3}\n",
    "from torch.utils import data\n",
    "\n",
    "class Dataset(data.Dataset):    \n",
    "    def __init__(self, data_name, vocab, cutoff=None):\n",
    "        data = json.load(open(data_name, 'r'))\n",
    "        sum_list = data['summary']\n",
    "        data_list = data['document']\n",
    "        \n",
    "        if cutoff is not None:\n",
    "            sum_list = sum_list[:cutoff]\n",
    "            data_list = data_list[:cutoff]\n",
    "        # idata -> list\n",
    "        self.size = len(sum_list)\n",
    "        self.dataset = []\n",
    "        self.sum_len = 0\n",
    "        \n",
    "        for i in tqdm(range(len(sum_list))):\n",
    "            if(len(data_list[i]) <= INPUT_MAX):\n",
    "                data = [vocab['<pad>']]*(INPUT_MAX-len(data_list[i])) + data_list[i]\n",
    "            else:\n",
    "                data = data_list[i][:INPUT_MAX]\n",
    "                \n",
    "            if(len(sum_list[i]) <= OUTPUT_MAX):\n",
    "                sum_in = sum_list[i] + [vocab['<pad>']]*(OUTPUT_MAX-len(sum_list[i]))\n",
    "            else:\n",
    "                sum_in = sum_list[i][:OUTPUT_MAX]\n",
    "                \n",
    "            sum_out_raw = sum_list[i][1:]\n",
    "            if(len(sum_out_raw) <= OUTPUT_MAX):\n",
    "                sum_out = sum_out_raw + [vocab['<pad>']]*(OUTPUT_MAX-len(sum_out_raw))\n",
    "            else:\n",
    "                sum_out = sum_out_raw[:OUTPUT_MAX]\n",
    "                \n",
    "            self.dataset.append([data, sum_in, sum_out])\n",
    "     \n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "    def __getitem__(self, index):\n",
    "        # output ari sum sumout\n",
    "#         print([vocab['<bos>']]+self.dataset[index][1]+[vocab['<eos>']])\n",
    "        return (torch.tensor(self.dataset[index][0]),\\\n",
    "                torch.tensor(self.dataset[index][1]),\\\n",
    "                torch.tensor(self.dataset[index][2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40cbf4742c1b4c7cab09faa063ff78f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=284367), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d986dd551414320a7b236aa4587a9ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2860), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "training_set = Dataset(data_name, vocab)\n",
    "validation_set = Dataset(validation_name, vocab, cutoff=validation_size)\n",
    "params = {'batch_size':8,\n",
    "         'shuffle': True,\n",
    "         'num_workers': 4}\n",
    "training_generator = data.DataLoader(training_set, **params)\n",
    "validation_generator = data.DataLoader(validation_set, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PointerGenerator(HIDDEN_DIM, EMB_DIM, INPUT_MAX, OUTPUT_MAX, VOC_SIZE, word_vectors, coverage=True).to(device)\n",
    "# optimizer = torch.optim.RMSprop(model.parameters(), lr=1e-3)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-5, weight_decay=1e-6)\n",
    "\n",
    "if continue_from is None:    \n",
    "    epoch = 0\n",
    "else:\n",
    "    saved_model = torch.load(continue_from)\n",
    "    model.load_state_dict(saved_model['model'])    \n",
    "    epoch = int(saved_model['epoch'] // 1) + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class PointerGenerator2(nn.Module):\n",
    "#     def __init__(self, hidden_dim, emb_dim, input_len, output_len, voc_size, word_vectors=None, eps=1e-10, coverage=False):\n",
    "#         super(PointerGenerator2, self).__init__()\n",
    "        \n",
    "#         self.hidden_dim = hidden_dim\n",
    "#         self.emb_dim = emb_dim\n",
    "#         self.input_len = input_len\n",
    "#         self.output_len = output_len\n",
    "#         self.voc_size = voc_size\n",
    "#         self.teacher_prob = 1.\n",
    "#         self.epsilon = eps\n",
    "#         self.coverage = coverage\n",
    "        \n",
    "#         self.emb_layer = model.emb_layer\n",
    "#         self.encoder = model.encoder\n",
    "#         self.decoder = model.decoder\n",
    "        \n",
    "#         self.attention_softmax = model.attention_softmax\n",
    "        \n",
    "#         self.pro_layer = model.pro_layer\n",
    "#         self.pgen_layer = model.pgen_layer\n",
    "        \n",
    "#         self.cov_weight = nn.Parameter(torch.randn(1, dtype=torch.float)/10)\n",
    "        \n",
    "# model2 = PointerGenerator2(HIDDEN_DIM, EMB_DIM, INPUT_MAX, OUTPUT_MAX, VOC_SIZE, word_vectors, coverage=True).to(device)\n",
    "\n",
    "# torch.save({\n",
    "#                 'epoch': epoch - 1,\n",
    "#                 'loss': saved_model['loss'],\n",
    "#                 'val_loss': saved_model['val_loss'],\n",
    "#                 'model': model2.state_dict()\n",
    "#             }, './models/covModel' + str(epoch-1))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = torch.nn.NLLLoss(ignore_index=vocab['<pad>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, valid_gen):\n",
    "    vlosses = []\n",
    "    with torch.no_grad():\n",
    "        for vi, (vin1, vin2, vout) in enumerate(validation_generator):\n",
    "            vin1, vin2, vout = vin1.to(device), vin2.to(device), vout.to(device)\n",
    "\n",
    "            vpredict, covloss = model.forward(vin1, vin2) ## teacher\n",
    "#             vpredict = model.forward(vin1, vin2, 0.) ## full decode\n",
    "            vloss = loss_function(vpredict.view(vpredict.shape[0]*vpredict.shape[1], VOC_SIZE), vout.view(vout.shape[0]*vout.shape[1]))\n",
    "            vlosses.append(vloss.item())\n",
    "    return sum(vlosses) / (len(vlosses)+epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cf8bc42fe8f431391e903af9d53697b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=35546), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9238118674169735 0.07659244537353516 -1.15426385402679441\n",
      "val_loss: 2.982838207116173\n",
      "2.9109369034716477 0.07607347518205643 -1.15918290615081793\n",
      "val_loss: 2.9804309806335905\n",
      "2.9161628306549545 0.08453889936208725 -1.15978419780731223\n",
      "val_loss: 2.9751662042545557\n",
      "2.9162335401401505 0.0825531929731369 -1.162144899368286197\n",
      "val_loss: 2.979126229964655\n",
      "2.9133666700815715 0.08794687688350677 -1.16031718254089368\n",
      "val_loss: 2.97895218340295\n",
      "2.911317778267838 0.07796411216259003 -1.164819002151489336\n",
      "val_loss: 2.973126296889684\n",
      "2.9114860364302078 0.06331135332584381 -1.16598284244537359\n",
      "val_loss: 2.972892109241401\n",
      "2.91168302490386 0.07533876597881317 -1.1669613122940063376\n",
      "val_loss: 2.974148467931503\n",
      "2.9114834577586124 0.07967305928468704 -1.17215764522552533\n",
      "val_loss: 2.974524546601088\n",
      "2.913330653994435 0.08784729987382889 -1.172015309333801335\n",
      "val_loss: 2.9680621620654764\n",
      "2.9141482907292735 0.06932928413152695 -1.17220580577850342\n",
      "val_loss: 2.9671010747959863\n",
      "2.913608938903667 0.08187268674373627 -1.175118923187255933\n",
      "val_loss: 2.967937327629198\n",
      "2.9134884584622145 0.0761280357837677 -1.177291393280029392\n",
      "val_loss: 2.968558506591863\n",
      "2.913399891103427 0.08641663193702698 -1.182096481323242273\n",
      "val_loss: 2.9656916157485096\n",
      "2.913148974531216 0.09184012562036514 -1.182559609413147146\n",
      "loss: 2.913148974531216\n",
      "Epoch 7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "952cd2b8ea0d472cad2828e346709851",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=35546), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8829459402152726 0.06724505126476288 -1.18016541004180961\n",
      "val_loss: 2.967766378511101\n",
      "2.8843806076357827 0.08148952573537827 -1.18064033985137945\n",
      "val_loss: 2.9681600745155525\n",
      "2.8835949322501393 0.0825953334569931 -1.183231830596923846\n",
      "val_loss: 2.9656995178592647\n",
      "2.8843777030442506 0.10143079608678818 -1.18688428401947025\n",
      "val_loss: 2.9642222347197964\n",
      "2.8855992440969134 0.07087964564561844 -1.19099617004394535\n",
      "val_loss: 2.964073338987279\n",
      "2.8846577248380236 0.07225760072469711 -1.18833374977111822\n",
      "val_loss: 2.964358540885779\n",
      "2.8885186619826446 0.08442594110965729 -1.19077777862548833\n",
      "val_loss: 2.9593787656141783\n",
      "2.887278992866835 0.07139317691326141 -1.195430636405944839\n",
      "val_loss: 2.962925726474169\n",
      "2.8876992970894064 0.06562183797359467 -1.19702970981597915\n",
      "val_loss: 2.967258476011417\n",
      "2.8880464886222224 0.07324668020009995 -1.19461107254028322\n",
      "val_loss: 2.9596244409755346\n",
      "2.889097456534869 0.07138185948133469 -1.194617271423339862\n",
      "val_loss: 2.963972473609885\n",
      "2.8896076268357342 0.08360052108764648 -1.19529330730438232\n",
      "val_loss: 2.9591772526327853\n",
      "2.889513543505803 0.07377270609140396 -1.194748163223266692\n",
      "val_loss: 2.9558542866938344\n",
      "2.890088568592665 0.08355393260717392 -1.194410324096679766\n",
      "val_loss: 2.956765407289713\n",
      "2.8899879422499293 0.09151199460029602 -1.19482350349426278\n",
      "loss: 2.8899879422499293\n",
      "Epoch 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a17c04b2097412dac866772f3a06b0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=35546), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.853701148543968 0.07540273666381836 -1.194965600967407277\n",
      "val_loss: 2.9594898207219344\n",
      "2.8632902555799555 0.09399731457233429 -1.19575774669647227\n",
      "val_loss: 2.9628128978784907\n",
      "2.865143145384234 0.07022473216056824 -1.196420788764953668\n",
      "val_loss: 2.9595829065277317\n",
      "2.867405683525603 0.0710943192243576 -1.1977131366729736346\n",
      "val_loss: 2.9551684889705228\n",
      "2.868992186743117 0.06709316372871399 -1.198863863945007354\n",
      "val_loss: 2.9616872308632236\n",
      "2.8704050432866595 0.055935367941856384 -1.2005281448364258\n",
      "val_loss: 2.955148843745786\n",
      "2.8710112460376718 0.08304592221975327 -1.20022845268249519\n",
      "val_loss: 2.9564596534433045\n",
      "2.871028612508048 0.07257931679487228 -1.203784584999084582\n",
      "val_loss: 2.9545687117381876\n",
      "2.8720308350293666 0.07024525851011276 -1.20548200607299898\n",
      "val_loss: 2.9588430107630557\n",
      "2.8723309487570097 0.07340016216039658 -1.20518517494201663\n",
      "val_loss: 2.9579103322660187\n",
      "2.8721575227360496 0.0853748470544815 -1.207008957862854732\n",
      "val_loss: 2.952262439540486\n",
      "2.872796053327435 0.08227157592773438 -1.210325837135315822\n",
      "val_loss: 2.9517709982453524\n",
      "2.8734954873118372 0.0656057745218277 -1.209364056587219227\n",
      "val_loss: 2.952677752051781\n",
      "2.8738574786549393 0.06449712812900543 -1.21288311481475839\n",
      "val_loss: 2.953822790243613\n",
      "2.8747721054823216 0.07306840270757675 -1.21441149711608893\n",
      "loss: 2.8747721054823216\n",
      "Epoch 9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "179eb8ad8612413a8b48a2c57c0e35ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=35546), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8455965693367675 0.06539100408554077 -1.21368491649627698\n",
      "val_loss: 2.956498902269422\n",
      "2.8486757790155526 0.07902847230434418 -1.21808457374572756\n",
      "val_loss: 2.951428675117947\n",
      "2.851537873056435 0.07045388966798782 -1.221939921379089437\n",
      "val_loss: 2.9577519560651138\n",
      "2.8539770283988646 0.0731828436255455 -1.219545602798462665\n",
      "val_loss: 2.9547737420595963\n",
      "2.857980412745021 0.08748210966587067 -1.217201232910156267\n",
      "val_loss: 2.9589832012205544\n",
      "2.857566317333696 0.058413855731487274 -1.21877753734588623\n",
      "val_loss: 2.9538536404755935\n",
      "2.8577789876480755 0.07212791591882706 -1.22111487388610849\n",
      "val_loss: 2.9526402370881515\n",
      "2.85807928932701 0.06730855256319046 -1.2196600437164307272\n",
      "val_loss: 2.9488288517096612\n",
      "2.857944864206576 0.09005158394575119 -1.219484210014343346\n",
      "val_loss: 2.9538314335830793\n",
      "2.8588499716904923 0.09337694197893143 -1.22174251079559338\n",
      "val_loss: 2.951834317025367\n",
      "2.8587447581966203 0.0901583656668663 -1.226122260093689647\n",
      "val_loss: 2.9519756965788795\n",
      "2.859480809344157 0.07587533444166183 -1.225995063781738321\n",
      "val_loss: 2.9494879355635475\n",
      "2.860873266624225 0.07181064039468765 -1.226276040077209513\n",
      "val_loss: 2.950331842432317\n",
      "2.8615164637455623 0.07626837491989136 -1.22675132751464845\n",
      "val_loss: 2.949402977633585\n",
      "2.8612910027993066 0.055786170065402985 -1.2247121334075928\n",
      "loss: 2.8612910027993066\n",
      "Epoch 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6f1e376919244788e3dea2cfa54c59d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=35546), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8401937452441905 0.09029575437307358 -1.22715640068054222\n",
      "val_loss: 2.9512185627513507\n",
      "2.839367817007613 0.0880170613527298 -1.2279794216156006453\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-e955075e012c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0min1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0min1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mpredict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcovloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/speechlab/data/PointerGenerator.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, ans)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m             \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mout_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_c\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mout_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_c\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoverage\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             result = _impl(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0;32m--> 179\u001b[0;31m                            self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    180\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             result = _impl(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "val_losses = []\n",
    "while epoch <= num_epochs:\n",
    "    \n",
    "\n",
    "    print(\"Epoch\", epoch)\n",
    "    running_loss = 0.0\n",
    "    iters = int(math.ceil(len(training_set)/params['batch_size']))\n",
    "    for i, (in1, in2, out) in tqdm(enumerate(training_generator), total=iters):\n",
    "        in1, in2, out = in1.to(device), in2.to(device), out.to(device)\n",
    "\n",
    "        predict, covloss = model.forward(in1, in2)\n",
    "        \n",
    "        if torch.isnan(predict).any():\n",
    "            raise RuntimeError\n",
    "        \n",
    "        loss = loss_function(predict.view(predict.shape[0]*predict.shape[1], VOC_SIZE), out.view(out.shape[0]*out.shape[1]))\n",
    "        loss = loss + 1. * covloss[0]\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        # gradient clipping\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=clip_grad_norm, norm_type=2)\n",
    "        optimizer.step()\n",
    "        \n",
    "        if np.isnan(loss.item()):\n",
    "            raise RuntimeError\n",
    "        running_loss += loss.item()\n",
    "                \n",
    "        if i % 2400 == 2399:\n",
    "            val_loss = validate(model, validation_generator)\n",
    "            train_losses.append(running_loss/(i+1))\n",
    "            val_losses.append(val_loss)\n",
    "            print('\\nval_loss:', val_loss)            \n",
    "        \n",
    "#         print(running_loss/(i+1), end='\\r')\n",
    "        print(running_loss/(i+1), covloss[0].item(), model.cov_weight.item(),   end='\\r')\n",
    "    print('loss:', running_loss / iters)\n",
    "#     train_losses.append(running_loss / iters)\n",
    "    if epoch % save_rate == 0:\n",
    "        torch.save({\n",
    "                'epoch': epoch,\n",
    "                'loss': train_losses,\n",
    "                'val_loss': val_losses,\n",
    "                'model': model.state_dict()\n",
    "            }, './models/covModel' + str(epoch))    \n",
    "    \n",
    "    epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate(model, validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
