{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer_nb import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "# from tqdm import tqdm\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = '../pointer-generator/preprocessing-cnn-all/'\n",
    "# folder = '../pointer-generator/preprocessing-300d-all/'\n",
    "data_name = folder+'train_seq.json'\n",
    "validation_name = folder+'valid_seq.json'\n",
    "testdata_name = folder+'testdata_seq.json'\n",
    "vocab_name = folder+'vocab.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "save_rate = 1 #how many epochs per modelsave\n",
    "continue_from = \"trained/Model3\" # if none, put None\n",
    "continue_from = None\n",
    "epsilon = 1e-10\n",
    "validation_size = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = json.load(open(vocab_name, 'r'))\n",
    "VOC_SIZE = len(vocab)\n",
    "INPUT_MAX = 400\n",
    "OUTPUT_MAX = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import data\n",
    "\n",
    "class Dataset(data.Dataset):    \n",
    "    def __init__(self, data_name, vocab, cutoff=None):\n",
    "        print(\"loading json\")\n",
    "        data = json.load(open(data_name, 'r'))\n",
    "        print(\"load json done.\")\n",
    "        sum_list = data['summary']\n",
    "        data_list = data['document']\n",
    "        \n",
    "        if cutoff is not None:\n",
    "            sum_list = sum_list[:cutoff]\n",
    "            data_list = data_list[:cutoff]\n",
    "        # idata -> list\n",
    "        self.size = len(sum_list)\n",
    "        self.dataset = []\n",
    "        self.sum_len = 0\n",
    "        \n",
    "        for i in tqdm(range(len(sum_list))):\n",
    "            if(len(data_list[i]) <= INPUT_MAX):\n",
    "                data = [vocab['<pad>']]*(INPUT_MAX-len(data_list[i])) + data_list[i]\n",
    "            else:\n",
    "                data = data_list[i][:INPUT_MAX]\n",
    "                \n",
    "            if(len(sum_list[i]) <= OUTPUT_MAX):\n",
    "                sum_in = sum_list[i] + [vocab['<pad>']]*(OUTPUT_MAX-len(sum_list[i]))\n",
    "            else:\n",
    "                sum_in = sum_list[i][:OUTPUT_MAX]\n",
    "                \n",
    "            self.dataset.append([data, sum_in])\n",
    "     \n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "    def __getitem__(self, index):\n",
    "        return torch.tensor(self.dataset[index][0]), torch.tensor(self.dataset[index][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading json\n",
      "load json done.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfa71a71894840d6aaa918c151443266",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=284367), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "loading json\n",
      "load json done.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5076d1705dc491180e8700bfd42e94e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2860), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "training_set = Dataset(data_name, vocab)\n",
    "validation_set = Dataset(validation_name, vocab, cutoff=validation_size)\n",
    "params = {'batch_size':batch_size,\n",
    "         'shuffle': True,\n",
    "         'num_workers': 4}\n",
    "training_generator = data.DataLoader(training_set, **params)\n",
    "validation_generator = data.DataLoader(validation_set, **params)\n",
    "\n",
    "def data_gen_train():\n",
    "    for src,tgt in training_generator:\n",
    "        src = Variable(src, requires_grad=False).to(device)\n",
    "        tgt = Variable(tgt, requires_grad=False).to(device)\n",
    "        yield Batch(src, tgt, vocab['<pad>'])\n",
    "def data_gen_val():\n",
    "    for src,tgt in validation_generator:\n",
    "        src = Variable(src, requires_grad=False).to(device)\n",
    "        tgt = Variable(tgt, requires_grad=False).to(device)\n",
    "        yield Batch(src, tgt, vocab['<pad>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28437 286\n"
     ]
    }
   ],
   "source": [
    "total_train = int(math.ceil(training_set.size / batch_size))\n",
    "total_valid = int(math.ceil(validation_set.size / batch_size))\n",
    "print(total_train, total_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/george/.conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/_reduction.py:49: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EncoderDecoder(\n",
       "  (encoder): Encoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): EncoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (3): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (w_2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (sublayer): ModuleList(\n",
       "          (0): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (1): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): EncoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (3): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (w_2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (sublayer): ModuleList(\n",
       "          (0): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (1): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): EncoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (3): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (w_2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (sublayer): ModuleList(\n",
       "          (0): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (1): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): EncoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (3): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (w_2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (sublayer): ModuleList(\n",
       "          (0): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (1): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm()\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): DecoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (3): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (src_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (3): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (w_2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (sublayer): ModuleList(\n",
       "          (0): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (1): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (2): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): DecoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (3): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (src_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (3): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (w_2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (sublayer): ModuleList(\n",
       "          (0): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (1): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (2): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): DecoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (3): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (src_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (3): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (w_2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (sublayer): ModuleList(\n",
       "          (0): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (1): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (2): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): DecoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (3): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (src_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (3): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (w_2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (sublayer): ModuleList(\n",
       "          (0): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (1): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (2): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm()\n",
       "  )\n",
       "  (src_embed): Sequential(\n",
       "    (0): Embeddings(\n",
       "      (lut): Embedding(90000, 256)\n",
       "    )\n",
       "    (1): PositionalEncoding(\n",
       "      (dropout): Dropout(p=0.1)\n",
       "    )\n",
       "  )\n",
       "  (tgt_embed): Sequential(\n",
       "    (0): Embeddings(\n",
       "      (lut): Embedding(90000, 256)\n",
       "    )\n",
       "    (1): PositionalEncoding(\n",
       "      (dropout): Dropout(p=0.1)\n",
       "    )\n",
       "  )\n",
       "  (generator): Generator(\n",
       "    (proj): Linear(in_features=256, out_features=90000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion = LabelSmoothing(size=VOC_SIZE, padding_idx=vocab['<pad>'], smoothing=0.1)\n",
    "# model = make_model(VOC_SIZE, VOC_SIZE, N=6, d_model=512, d_ff=2048, h=8, dropout=0.1)\n",
    "model = make_model(VOC_SIZE, VOC_SIZE, N=4, d_model=256, d_ff=1024, h=8, dropout=0.1)\n",
    "\n",
    "\n",
    "if continue_from == None:\n",
    "    model_opt = NoamOpt(model.src_embed[0].d_model, 1, 4000,\n",
    "            torch.optim.Adam(model.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9))\n",
    "else:\n",
    "    saved_model = torch.load(continue_from)\n",
    "    model.load_state_dict(saved_model['model'])\n",
    "    model_opt = saved_model['optim']\n",
    "\n",
    "criterion.cuda()\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.cuda()\n",
    "# criterion.cuda()\n",
    "for epoch in range(num_epochs):\n",
    "    print(\"Epoch\", epoch)\n",
    "        \n",
    "    model.train()\n",
    "    run_epoch(data_gen_train(), model, \n",
    "              SimpleLossCompute(model.generator, criterion, model_opt), total=total_train)\n",
    "    model.eval()\n",
    "    run_epoch(data_gen_val(), model, \n",
    "                    SimpleLossCompute(model.generator, criterion, None), total=total_valid)\n",
    "    try:\n",
    "        torch.save({'model':model.state_dict(),\n",
    "                   'optim': model_opt, }, 'trained/Model'+str(epoch))\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
    "    memory = model.encode(src, src_mask)\n",
    "    ys = torch.ones(1, 1).fill_(start_symbol).type_as(src.data)\n",
    "    for i in range(max_len-1):\n",
    "        out = model.decode(memory, src_mask, \n",
    "                           Variable(ys), \n",
    "                           Variable(subsequent_mask(ys.size(1))\n",
    "                                    .type_as(src.data)))\n",
    "        prob = model.generator(out[:, -1])\n",
    "        _, next_word = torch.max(prob, dim = 1)\n",
    "        next_word = next_word.data[0]\n",
    "        ys = torch.cat([ys, \n",
    "                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=1)\n",
    "    return ys\n",
    "\n",
    "def readable(sent):\n",
    "    try:\n",
    "        end = sent.index('<eos>')\n",
    "    except ValueError:\n",
    "        end = len(sent)\n",
    "    sent = \" \".join(sent[:end])\n",
    "    sent = sent.replace(\"<bos>\", '')\n",
    "    sent = sent.replace(\"<eos>\", '')\n",
    "    sent = sent.replace(\"<unk>\", '-UNK-')\n",
    "    sent = sent.replace(\"<pad>\", '')\n",
    "    return sent\n",
    "\n",
    "vocab_inv = {i:w for w, i in vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 8 is out of bounds for dimension 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-6ffd31f07d79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mtrg_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrg_masks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0msrc_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvocab_inv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 8 is out of bounds for dimension 0 with size 1"
     ]
    }
   ],
   "source": [
    "saved_model = torch.load('trained/Model9')\n",
    "model.load_state_dict(saved_model['model'])\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[input]\n",
      "  baghdad , iraq -lrb- cnn -rrb- -- brad blauser lives in war-torn baghdad , where he does n't earn a paycheck and is thousands of miles from his family . but he has no intention of leaving anytime soon . since 2005 , brad blauser 's wheelchairs for iraqi kids program has distributed nearly 650 free wheelchairs . for the past four years , the dallas , texas , native has been providing hope to hundreds of disabled iraqi children and their families through the distribution of pediatric wheelchairs . `` disabled children -- they 're really the forgotten ones in this war , `` said blauser , 43 . `` they are often not seen in society . `` blauser arrived in iraq as a civilian contractor in 2004 , but quit that job last year to devote himself full time to his program , without compensation . vote now for the cnn hero of the year . `` there 's no paycheck . it 's not really safe here . but this is a once-in-a-lifetime opportunity , `` he said . an estimated one in seven iraqi children ages 2 to 14 lives with a disability , according to unicef . illnesses such as spina bifida , palsy and polio leave them unable to walk . some parents carry their children every day . for these children and their families , limited access to health care has taken a toll . `` a number of families do n't know what 's wrong with their kid . there 's not a doctor available for help -lsb- and -rsb- there 's no pediatric wheelchair source in this country , `` blauser said . blauser first learned about this situation in 2005 through maj. david brown , a battalion surgeon . his friend shared heartbreaking accounts of helpless children pulling themselves along the ground , or living motionless in back rooms , too big to be moved long distances very often . `` so i asked him , ` what do you need ? ' '' blauser recalled . `` and he surprised me by his answer : ' i need children 's wheelchairs . ' '' blauser began researching and campaigning for help from friends and family in the united states . in 30 days , 31 pediatric and small adult wheelchairs arrived in mosul for distribution to children\n",
      "[target]\n",
      "  brad blauser 's wheelchairs for iraqi kids has distributed nearly 650 free wheelchairs . dallas native blauser lives in baghdad and works for free . `` disabled children -- they 're really the forgotten ones in this war , `` he said . vote now for the cnn hero of the year at cnn.com / heroes .\n",
      "[output]\n",
      "  brad . brad . `` the disabled `` is a special hero of the year . he 's been a disabled child for four years . he 's been a hero for the past four years .\n"
     ]
    }
   ],
   "source": [
    "for j,batch in enumerate(data_gen_val()):\n",
    "    srcs = batch.src\n",
    "    src_masks = batch.src_mask\n",
    "    \n",
    "    trgs = batch.trg\n",
    "    trg_masks = batch.trg_mask\n",
    "        \n",
    "    bs = srcs.shape[0]\n",
    "    \n",
    "    \n",
    "    for i in range(bs):    \n",
    "        if i + j*bs == 99:           \n",
    "        \n",
    "            src = srcs[i]\n",
    "            trg = trgs[i]\n",
    "            src_mask = src_masks[i]\n",
    "            trg_mask = trg_masks[i]\n",
    "\n",
    "            out = greedy_decode(model, src.view(1, -1), None, max_len=100, start_symbol=vocab['<bos>'])\n",
    "            out = out.view(-1)\n",
    "\n",
    "            src_words = [vocab_inv[idx.item()] for idx in src]\n",
    "            trg_words = [vocab_inv[idx.item()] for idx in trg]\n",
    "            out_words = [vocab_inv[idx.item()] for idx in out]\n",
    "\n",
    "            print('[input]\\n', readable(src_words))\n",
    "            print('[target]\\n', readable(trg_words))\n",
    "            print('[output]\\n', readable(out_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
