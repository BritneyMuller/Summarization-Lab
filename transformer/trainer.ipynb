{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer_nb import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "# from tqdm import tqdm\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder = '../pointer-generator/preprocessing-cnn-all/'\n",
    "folder = 'data-giga-light/'\n",
    "data_name = folder+'train_seq.json'\n",
    "validation_name = folder+'valid_seq.json'\n",
    "testdata_name = folder+'testdata_seq.json'\n",
    "vocab_name = folder+'vocab.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "save_rate = 1 #how many epochs per modelsave\n",
    "continue_from = \"trained/Model2\" # if none, put None\n",
    "continue_from = None\n",
    "epsilon = 1e-8\n",
    "validation_size = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = json.load(open(vocab_name, 'r'))\n",
    "VOC_SIZE = len(vocab)\n",
    "INPUT_MAX = 50\n",
    "OUTPUT_MAX = 20\n",
    "UNK = \"[UNK]\"\n",
    "BOS = \"[CLS]\"\n",
    "EOS = \"[SEP]\"\n",
    "PAD = \"[PAD]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading json\n",
      "load json done.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5408114256194b4fabebe905a83e88fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3796356), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "loading json\n",
      "load json done.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f76f7a4c5d7a44baa6ce84bf42568beb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7601), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from dataset import make_data_generator\n",
    "\n",
    "batch_size = 200\n",
    "\n",
    "training_set, training_generator = make_data_generator(\\\n",
    "data_name, INPUT_MAX, OUTPUT_MAX, vocab[PAD], batch_size, cutoff=None, shuffle=True, num_workers=4)\n",
    "\n",
    "validation_set, validation_generator = make_data_generator(\\\n",
    "validation_name, INPUT_MAX, OUTPUT_MAX, vocab[PAD], batch_size, cutoff=validation_size, shuffle=False, num_workers=4)\n",
    "\n",
    "def data_gen_train():\n",
    "    for src,tgt in training_generator:\n",
    "        src = Variable(src, requires_grad=False).to(device)\n",
    "        tgt = Variable(tgt, requires_grad=False).to(device)\n",
    "        yield Batch(src, tgt, vocab[PAD])\n",
    "def data_gen_val():\n",
    "    for src,tgt in validation_generator:\n",
    "        src = Variable(src, requires_grad=False).to(device)\n",
    "        tgt = Variable(tgt, requires_grad=False).to(device)\n",
    "        yield Batch(src, tgt, vocab[PAD])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18982 39\n"
     ]
    }
   ],
   "source": [
    "total_train = int(math.ceil(training_set.size / batch_size))\n",
    "total_valid = int(math.ceil(validation_set.size / batch_size))\n",
    "print(total_train, total_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EncoderDecoder(\n",
       "  (encoder): Encoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): EncoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (3): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (w_2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (sublayer): ModuleList(\n",
       "          (0): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (1): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): EncoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (3): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (w_2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (sublayer): ModuleList(\n",
       "          (0): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (1): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): EncoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (3): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (w_2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (sublayer): ModuleList(\n",
       "          (0): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (1): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): EncoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (3): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (w_2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (sublayer): ModuleList(\n",
       "          (0): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (1): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm()\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): DecoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (3): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (src_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (3): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (w_2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (sublayer): ModuleList(\n",
       "          (0): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (1): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (2): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): DecoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (3): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (src_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (3): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (w_2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (sublayer): ModuleList(\n",
       "          (0): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (1): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (2): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): DecoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (3): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (src_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (3): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (w_2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (sublayer): ModuleList(\n",
       "          (0): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (1): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (2): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): DecoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (3): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (src_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (3): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (w_2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (sublayer): ModuleList(\n",
       "          (0): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (1): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (2): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm()\n",
       "  )\n",
       "  (src_embed): Sequential(\n",
       "    (0): Embeddings(\n",
       "      (lut): Embedding(30522, 256)\n",
       "    )\n",
       "    (1): PositionalEncoding(\n",
       "      (dropout): Dropout(p=0.1)\n",
       "    )\n",
       "  )\n",
       "  (tgt_embed): Sequential(\n",
       "    (0): Embeddings(\n",
       "      (lut): Embedding(30522, 256)\n",
       "    )\n",
       "    (1): PositionalEncoding(\n",
       "      (dropout): Dropout(p=0.1)\n",
       "    )\n",
       "  )\n",
       "  (generator): Generator(\n",
       "    (proj): Linear(in_features=256, out_features=30522, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#criterion = nn.CrossEntropyLoss(ignore_index=vocab[PAD], reduction='sum') \n",
    "#LabelSmoothing(size=VOC_SIZE, padding_idx=vocab[PAD], smoothing=0.0)\n",
    "criterion = nn.NLLLoss(ignore_index=vocab[PAD], reduction='sum')\n",
    "\n",
    "#model = make_model(VOC_SIZE, VOC_SIZE, N=12, d_model=768, d_ff=768, h=12, dropout=0.1)\n",
    "# model = make_model(VOC_SIZE, VOC_SIZE, N=6, d_model=512, d_ff=2048, h=8, dropout=0.1)\n",
    "model = make_model(VOC_SIZE, VOC_SIZE, N=4, d_model=256, d_ff=1024, h=8, dropout=0.1)\n",
    "\n",
    "\n",
    "if continue_from == None:\n",
    "    model_opt = torch.optim.Adam(model.parameters(), lr=1e-4, betas=(0.9, 0.98), eps=1e-9)\n",
    "#     model_opt.factor = 3.\n",
    "#     model_opt = NoamOpt(model.src_embed[0].d_model, 3., 4000,\n",
    "#             torch.optim.Adam(model.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9))\n",
    "else:\n",
    "    saved_model = torch.load(continue_from)\n",
    "    model.load_state_dict(saved_model['model'])\n",
    "    model_opt = torch.optim.Adam(model.parameters(), lr=1e-4, betas=(0.9, 0.98), eps=1e-9)\n",
    "\n",
    "    \n",
    "criterion.cuda()\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f599323f987744fd9b19da51cb81c790",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=18982), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.7209248542785645\r"
     ]
    }
   ],
   "source": [
    "train_history = []\n",
    "valid_history = []\n",
    "start = 1 if continue_from == None else int(continue_from.split(\"Model\")[-1])\n",
    "for epoch in range(start, num_epochs+1):\n",
    "    print(\"Epoch\", epoch)\n",
    "        \n",
    "    model.train()\n",
    "    tl, th = run_epoch(data_gen_train(), model, \n",
    "              SimpleLossCompute(model.generator, criterion, model_opt), total=total_train)\n",
    "    \n",
    "    model.eval()\n",
    "    vl, vh = run_epoch(data_gen_val(), model, \n",
    "                    SimpleLossCompute(model.generator, criterion, None), total=total_valid)\n",
    "    print(\"epoch train loss:\", tl)\n",
    "    print(\"epoch val loss:\", vl)\n",
    "    \n",
    "    train_history.append(th)\n",
    "    valid_history.append(vl)\n",
    "    \n",
    "    try:\n",
    "        torch.save({'model':model.state_dict(),\n",
    "                   'optim': model_opt, \n",
    "                   'train_history': train_history,\n",
    "                   'valid_history': valid_history}, 'trained/Model'+str(epoch))\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_decode_batch(model, src, src_mask, max_len, start_symbol):\n",
    "    batch_size = src.shape[0]\n",
    "    \n",
    "    memory = model.encode(src, src_mask)\n",
    "    ys = torch.ones(batch_size, 1).fill_(start_symbol).type_as(src.data)\n",
    "    for i in range(max_len-1):\n",
    "        out = model.decode(memory, src_mask, \n",
    "                           Variable(ys), \n",
    "                           Variable(subsequent_mask(ys.size(1))\n",
    "                                    .type_as(src.data)))\n",
    "        #print(out.shape) 128,1,256\n",
    "        probs = model.generator(out[:, -1, :])\n",
    "        \n",
    "        #print(probs.shape) 128,30522\n",
    "        next_words = torch.argmax(probs, dim=1, keepdim=True)\n",
    "        \n",
    "        #print(next_words.shape)        \n",
    "        #print(ys.shape) both 128,1\n",
    "        \n",
    "        ys = torch.cat((ys, next_words), dim=1)\n",
    "    return ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_pretrained_bert.tokenization import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "# saved_model = torch.load(\"trained/Modelf\")\n",
    "# model.load_state_dict(saved_model['model'])\n",
    "model.eval()\n",
    "for batch in data_gen_val():    \n",
    "    srcs = batch.src\n",
    "    src_masks = batch.src_mask.byte()\n",
    "    \n",
    "    trgs = batch.trg\n",
    "    trg_masks = batch.trg_mask\n",
    "        \n",
    "    bs = srcs.shape[0]\n",
    "    \n",
    "    outs = greedy_decode_batch(model, srcs, None, max_len=OUTPUT_MAX, start_symbol=vocab[BOS])\n",
    "    \n",
    "    for j, (out_tensor, tgt_tensor) in enumerate(zip(outs, trgs)):        \n",
    "        tokens = tokenizer.convert_ids_to_tokens(out_tensor.cpu().numpy())  \n",
    "        print(tokens)\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
